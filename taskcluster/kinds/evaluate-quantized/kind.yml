# This Source Code Form is subject to the terms of the Mozilla Public
# License, v. 2.0. If a copy of the MPL was not distributed with this
# file, You can obtain one at http://mozilla.org/MPL/2.0/.
---

loader: taskgraph.loader.transform:loader

transforms:
    - translations_taskgraph.transforms.from_datasets:per_dataset
    - translations_taskgraph.transforms.worker_selection
    - taskgraph.transforms.task_context
    - taskgraph.transforms.run:transforms
    - translations_taskgraph.transforms.cached_tasks:transforms
    - taskgraph.transforms.task:transforms

kind-dependencies:
    - dataset
    - train-vocab
    - quantize
    - shortlist
    - toolchain

tasks:
    "{provider}-{dataset_sanitized}-{src_locale}-{trg_locale}":
        description: quantized evaluation for {dataset_sanitized} {src_locale}-{trg_locale}
        attributes:
            stage: evaluate-quantized
            dataset-category: test
            cache:
                type: evaluate-quantized
                resources:
                    - pipeline/eval/eval.py

        dataset-config:
            category: test
            substitution-fields:
                - description
                - name
                - dependencies
                - fetches
                - worker.env
                - task-context
                - run.command
        task-context:
            substitution-fields:
                - run.command
                - fetches
                - worker.env
            from-parameters:
                src_locale: training_config.experiment.src
                trg_locale: training_config.experiment.trg
                wandb_publication: training_config.wandb-publication
                owner: owner

        worker-type: b-gpu
        worker:
            docker-image: {"in-tree": "train"}
            artifacts:
                - name: public/build
                  path: /builds/worker/artifacts
                  type: directory
            max-run-time: 2592000
            env:
                # This is a separate environment variable so tests can override it.
                BMT_MARIAN: $MOZ_FETCHES_DIR

                # Weight & Biases trigger
                WANDB_PUBLICATION: "{wandb_publication}"
                WANDB_AUTHOR: "{owner}"

                # Weight & Biases publication token is stored in that secret
                TASKCLUSTER_SECRET: project/translations/level-1/weights-and-biases

            # Taskcluster proxy is required to read secrets
            taskcluster-proxy: true
            # 128 happens when cloning this repository fails
            retry-exit-status: [128]

        # The task needs to be able to read that secret to publish on Weight & Biases
        scopes:
          - secrets:get:project/translations/level-1/weights-and-biases

        # Don't run unless explicitly scheduled
        run-on-tasks-for: []

        run:
            using: run-task
            command:
                - bash
                - -c
                - >-
                    export PATH=$PATH:~/.local/bin &&
                    export PYTHONPATH=$PYTHONPATH:$VCS_PATH &&
                    pip install --upgrade pip &&
                    pip install -r $VCS_PATH/pipeline/eval/requirements/eval.txt &&
                    pip install $VCS_PATH/tracking &&
                    zstd --rm -d $MOZ_FETCHES_DIR/lex.s2t.pruned.zst &&
                    $VCS_PATH/pipeline/eval/eval.py
                    --src               {src_locale}
                    --trg               {trg_locale}
                    --models            "$MOZ_FETCHES_DIR/model.intgemm.alphas.bin"
                    --dataset_prefix    "$MOZ_FETCHES_DIR/{dataset_sanitized}"
                    --vocab             "$MOZ_FETCHES_DIR/vocab.spm"
                    --shortlist         "$MOZ_FETCHES_DIR/lex.s2t.pruned"
                    --artifacts_prefix  "$TASK_WORKDIR/artifacts/{dataset_sanitized}"
                    --marian_config     "$TASK_WORKDIR/$VCS_PATH/pipeline/quantize/decoder.yml"
                    --marian            "$BMT_MARIAN"
                    --gpus              "$GPUS"
                    --model_variant     quantized

        dependencies:
            dataset: dataset-{provider}-{dataset_sanitized}-{src_locale}-{trg_locale}
            train-vocab: train-vocab-{src_locale}-{trg_locale}
            quantize: quantize-{src_locale}-{trg_locale}
            shortlist: shortlist-{src_locale}-{trg_locale}
        fetches:
            dataset:
                - artifact: "{dataset_sanitized}.{src_locale}.zst"
                  extract: false
                - artifact: "{dataset_sanitized}.{trg_locale}.zst"
                  extract: false
            train-vocab:
                - artifact: vocab.spm
                  extract: false
            quantize:
                - artifact: model.intgemm.alphas.bin
            shortlist:
                - artifact: lex.s2t.pruned.zst
            toolchain:
                # Quantized models are only supported via the browsermt fork of Marian.
                # https://github.com/browsermt/marian-dev
                - browsermt-marian
