# This Source Code Form is subject to the terms of the Mozilla Public
# License, v. 2.0. If a copy of the MPL was not distributed with this
# file, You can obtain one at http://mozilla.org/MPL/2.0/.
#
# This kind primarily exists because these dataset fetches break
# some assumptions made the `job` transforms that treat the `fetch`
# kind specially.
---
loader: taskgraph.loader.transform:loader

transforms:
    - translations_taskgraph.transforms.from_datasets:per_dataset
    - translations_taskgraph.transforms.command_context_from_params:transforms
    - taskgraph.transforms.job:transforms
    - translations_taskgraph.transforms.cache:transforms
    - taskgraph.transforms.cached_tasks:transforms
    - taskgraph.transforms.task:transforms

task-defaults:
    worker-type: b-linux
    attributes:
        dataset-category: train
        cache:
            type: dataset
    dataset-config:
        substitution-fields:
            - name
            - label
            - treeherder.symbol
            - worker.env
    worker:
        docker-image: {in-tree: toolchain-build}
        max-run-time: 1800
        env:
            COMPRESSION_CMD: zstdmt
            ARTIFACT_EXT: zst
            SRC: "{src_locale}"
            TRG: "{trg_locale}"
        artifacts:
            - name: public/build
              path: /builds/worker/artifacts
              type: directory

    treeherder:
        symbol: "{provider}({dataset_short}-{src_locale}-{trg_locale})"
        platform: dataset/opt
    run-on-tasks-for: []
    run:
        using: run-task
        # Include this so `from_datasets` will add a number of other values to it.
        command-context: {}

tasks:
    flores:
        description: Fetch flores101 dataset
        label: dataset-flores-{dataset}-{src_locale}-{trg_locale}
        dataset-config:
            include-datasets:
                flores: {}
        attributes:
            cache:
                resources:
                    - pipeline/data/importers/corpus/flores.sh
                    - pipeline/data/download-corpus.sh
        run:
            command:
                - bash
                - -c
                - >-
                    $VCS_PATH/pipeline/data/download-corpus.sh
                    {dataset}
                    /builds/worker/artifacts/{dataset_sanitized}

    sacrebleu:
        description: Fetch sacrebleu dataset
        label: dataset-sacrebleu-{dataset}-{src_locale}-{trg_locale}
        dataset-config:
            include-datasets:
                sacrebleu: {}
        attributes:
            cache:
                resources:
                    - pipeline/data/importers/corpus/sacrebleu.sh
                    - pipeline/data/download-corpus.sh
        run:
            command:
                - bash
                - -c
                - >-
                    $VCS_PATH/pipeline/data/download-corpus.sh
                    {dataset}
                    /builds/worker/artifacts/{dataset_sanitized}

    opus:
        description: Fetch opus dataset
        # No slashes version of dataset used here because slashes break caches
        label: dataset-opus-{dataset_sanitized}-{src_locale}-{trg_locale}
        dataset-config:
            include-datasets:
                opus: {}
        attributes:
            cache:
                resources:
                    - pipeline/data/importers/corpus/opus.sh
                    - pipeline/data/download-corpus.sh
        run:
            command:
                - bash
                - -c
                - >-
                    $VCS_PATH/pipeline/data/download-corpus.sh
                    {dataset}
                    /builds/worker/artifacts/{dataset_sanitized}

    mtdata:
        description: Fetch mtdata dataset
        label: dataset-mtdata-{dataset}-{src_locale}-{trg_locale}
        dataset-config:
            include-datasets:
                mtdata: {}
        attributes:
            cache:
                resources:
                    - pipeline/data/importers/corpus/mtdata.sh
                    - pipeline/data/download-corpus.sh
        run:
            command:
                - bash
                - -c
                - >-
                    $VCS_PATH/pipeline/data/download-corpus.sh
                    {dataset}
                    /builds/worker/artifacts/{dataset_sanitized}

    news-crawl:
        description: Fetch news-crawl dataset
        label: dataset-news-crawl-{dataset_sanitized}-{src_locale}-{trg_locale}
        dataset-config:
            include-datasets:
                news-crawl: {}
        attributes:
            cache:
                resources:
                    - pipeline/data/importers/mono/news-crawl.sh
                    - pipeline/data/download-mono.sh
                from-parameters:
                    max_sent_src:
                        - training_config.experiment.mono-max-sentences-src
                    max_sent_trg:
                        - training_config.experiment.mono-max-sentences-trg
        run:
            command-context:
                from-parameters:
                    max_sent_src:
                        - training_config.experiment.mono-max-sentences-src
                    max_sent_trg:
                        - training_config.experiment.mono-max-sentences-trg
            command:
                - bash
                - -c
                - >-
                    $VCS_PATH/pipeline/data/download-mono.sh
                    {dataset}
                    {src_locale}
                    {max_sent_src}
                    /builds/worker/artifacts/{dataset_sanitized}.{src_locale}.zst &&
                    $VCS_PATH/pipeline/data/download-mono.sh
                    {dataset}
                    {trg_locale}
                    {max_sent_trg}
                    /builds/worker/artifacts/{dataset_sanitized}.{trg_locale}.zst
