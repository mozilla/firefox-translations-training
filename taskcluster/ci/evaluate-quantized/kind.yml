# This Source Code Form is subject to the terms of the Mozilla Public
# License, v. 2.0. If a copy of the MPL was not distributed with this
# file, You can obtain one at http://mozilla.org/MPL/2.0/.
---

loader: taskgraph.loader.transform:loader

transforms:
    - translations_taskgraph.transforms.from_datasets:per_dataset
    - taskgraph.transforms.task_context
    - taskgraph.transforms.job:transforms
    - translations_taskgraph.transforms.cached_tasks:transforms
    - taskgraph.transforms.task:transforms

kind-dependencies:
    - dataset
    - train-vocab
    - quantize
    - alignments
    - toolchain

task-defaults:
    attributes:
        cache:
            resources:
                - pipeline/eval/eval-gpu.sh
                - pipeline/eval/eval.sh
    dataset-config:
        category: test
        substitution-fields:
            - description
            - name
            - dependencies
            - fetches
            - worker.env
            - task-context
            - run.command
    task-context:
        substitution-fields:
            - run.command
            - fetches
        from-parameters:
            best_model: training_config.experiment.best-model
            src_locale: training_config.experiment.src
            trg_locale: training_config.experiment.trg
            # The two sed commands here are the unfortunate result of us consuming
            # a marian config that was produced by an earlier step. These configs
            # have hardcoded absolute paths to the models they were trained on,
            # and end invalid when used on a different machine. In theory it is
            # possible to adjust them at generation time to use relative paths,
            # but in practice we have not been able to make this work.
            pipeline_setup: >-
    worker-type: b-linux-v100-gpu
    worker:
        artifacts:
            - name: public/build
              path: artifacts
              type: directory
        max-run-time: 2592000
        env:
            SRC: "{src_locale}"
            TRG: "{trg_locale}"
            GPUS: "0"
            WORKSPACE: "8000"
            COMPRESSION_CMD: zstdmt
            ARTIFACT_EXT: zst

    # Don't run unless explicitly scheduled
    run-on-tasks-for: []

    run:
        using: run-task
        command:
            - bash
            - -c
            - >-
                pip install -r $VCS_PATH/pipeline/eval/requirements/eval.txt &&
                export PATH=$PATH:~/.local/bin &&
                export MARIAN=$MOZ_FETCHES_DIR &&
                export BMT_MARIAN=$MOZ_FETCHES_DIR &&
                zstd --rm -d $MOZ_FETCHES_DIR/lex.s2t.pruned.zst &&
                {pipeline_script}
                {pipeline_args1}
                $MOZ_FETCHES_DIR/vocab.spm
                $TASK_WORKDIR/artifacts/{dataset_sanitized}
                $TASK_WORKDIR/$VCS_PATH/pipeline/quantize/decoder.yml

tasks:
    "{provider}-{dataset_sanitized}-{src_locale}-{trg_locale}":
        description: quantized evaluation for {dataset_sanitized} {src_locale}-{trg_locale}
        attributes:
            stage: evaluate-quantized
            dataset-category: test
            cache:
                type: evaluate-quantized

        task-context:
            from-object:
                pipeline_script: $VCS_PATH/pipeline/eval/eval-quantized.sh
                pipeline_args1: >-
                    $MOZ_FETCHES_DIR/model.intgemm.alphas.bin
                    $MOZ_FETCHES_DIR/lex.s2t.pruned
                    $MOZ_FETCHES_DIR/{dataset_sanitized}

        dependencies:
            dataset: dataset-{provider}-{dataset_sanitized}-{src_locale}-{trg_locale}
            train-vocab: train-vocab-{src_locale}-{trg_locale}
            quantize: quantize-{src_locale}-{trg_locale}
            alignments: alignments-{src_locale}-{trg_locale}
        fetches:
            dataset:
                - artifact: "{dataset_sanitized}.{src_locale}.zst"
                  extract: false
                - artifact: "{dataset_sanitized}.{trg_locale}.zst"
                  extract: false
            train-vocab:
                - artifact: vocab.spm
                  extract: false
            quantize:
                - artifact: model.intgemm.alphas.bin
            alignments:
                - artifact: lex.s2t.pruned.zst
            toolchain:
                - browsermt-marian
