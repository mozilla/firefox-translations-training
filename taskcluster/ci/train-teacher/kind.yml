# This Source Code Form is subject to the terms of the Mozilla Public
# License, v. 2.0. If a copy of the MPL was not distributed with this
# file, You can obtain one at http://mozilla.org/MPL/2.0/.
---

loader: taskgraph.loader.transform:loader

transforms:
    - translations_taskgraph.transforms.marian_args:transforms
    - taskgraph.transforms.task_context
    - translations_taskgraph.transforms.cast_to
    - taskgraph.transforms.chunking
    - taskgraph.transforms.job:transforms
    - translations_taskgraph.transforms.cached_tasks:transforms
    - taskgraph.transforms.task:transforms

kind-dependencies:
    - merge-devset
    - merge-mono
    - merge-corpus
    - collect-mono-trg
    - train-vocab
    - toolchain

tasks:
    # double curly braces are used for the chunk substitutions because
    # this must first be formatted by task-context to get src and trg locale
    "{src_locale}-{trg_locale}-{{this_chunk}}/{{total_chunks}}":
        description: train teacher for {src_locale}-{trg_locale} {{this_chunk}}/{{total_chunks}}
        chunk:
            total-chunks: "{teacher_ensemble}"
            substitution-fields:
                - name
                - description
        cast-to:
            int:
                - chunk.total-chunks
        task-context:
            from-parameters:
                src_locale: training_config.experiment.src
                trg_locale: training_config.experiment.trg
                best_model: training_config.experiment.best-model
                teacher_ensemble: training_config.experiment.teacher-ensemble
            substitution-fields:
                - description
                - name
                - fetches
                - dependencies
                - run.command
                - attributes
                - chunk.total-chunks
        attributes:
            stage: train-teacher
            src_locale: "{src_locale}"
            trg_locale: "{trg_locale}"
            best_model: "{best_model}"
            cache:
                type: train-teacher
                resources:
                    - pipeline/train/configs/model/teacher.yml
                    - pipeline/train/configs/opustrainer/teacher.yml
                    - pipeline/train/configs/training/teacher.train.yml
                    - pipeline/train/train.sh
                from-parameters:
                    marian_args: training_config.marian-args.training-teacher
                    teacher-ensemble: training_config.experiment.teacher-ensemble
        worker-type: b-linux-v100-gpu-4-1tb
        expires-after: "90 days"
        worker:
            max-run-time: 2592000
            env:
                # TODO: what should we _actually_ use for the workspace value?
                # and should we centralize this, since it seems to depend on available
                # memory?
                WORKSPACE: "12000"
                # TODO: this needs to be updated, ideally to have the script detect
                # GPUs. it should _always_ be aligned with the # of GPUs on the intsance
                GPUS: "0 1 2 3"
                ARTIFACT_EXT: zst
                COMPRESSION_CMD: zstdmt
            artifacts:
                - name: public/build
                  path: artifacts
                  type: directory

        # Don't run unless explicitly scheduled
        run-on-tasks-for: []

        marian-args:
            from-parameters: training_config.marian-args.training-teacher
        run:
            using: run-task
            # order of comma separated datasets is important
            command:
                - bash
                - -cx
                - >-
                    pip3 install --upgrade pip setuptools &&
                    pip3 install -r $VCS_PATH/pipeline/train/requirements/train.txt &&
                    export PATH="$HOME/.local/bin:$PATH" &&
                    export MARIAN=$MOZ_FETCHES_DIR &&
                    $VCS_PATH/pipeline/train/train.sh
                    teacher
                    train
                    {src_locale}
                    {trg_locale}
                    $MOZ_FETCHES_DIR/corpus,$MOZ_FETCHES_DIR/mono
                    $MOZ_FETCHES_DIR/devset
                    $TASK_WORKDIR/artifacts
                    $MOZ_FETCHES_DIR/vocab.spm
                    {best_model}
                    None
                    {marian_args}

        dependencies:
            train-vocab: train-vocab-{src_locale}-{trg_locale}
            merge-devset: merge-devset-{src_locale}-{trg_locale}
            merge-corpus: merge-corpus-{src_locale}-{trg_locale}
            merge-mono-trg: merge-mono-trg-{trg_locale}
            collect-mono-trg: collect-mono-trg-{src_locale}-{trg_locale}

        fetches:
            toolchain:
                - marian
            train-vocab:
                - artifact: vocab.spm
                  extract: false
            merge-corpus:
                - artifact: corpus.{src_locale}.zst
                  extract: false
                - artifact: corpus.{trg_locale}.zst
                  extract: false
            merge-mono-trg:
                - artifact: mono.{trg_locale}.zst
                  extract: false
            collect-mono-trg:
                - artifact: mono.{src_locale}.zst
                  extract: false
            merge-devset:
                - artifact: devset.{src_locale}.zst
                  extract: false
                - artifact: devset.{trg_locale}.zst
                  extract: false
